import sys
from pathlib import Path
from unittest.mock import Mock

import requests

# Handle import paths for testing
sys.path.append(str(Path(__file__).parent.parent))


def test_wikipedia_search_init(monkeypatch):
    """Test initialization of Wikipedia search."""
    # Mock requests.get to avoid actual API calls
    monkeypatch.setattr("requests.get", lambda *args, **kwargs: None)

    from src.local_deep_research.web_search_engines.wikipedia_search import (
        WikipediaSearch,
    )

    # Create search engine with default parameters
    search = WikipediaSearch()

    # Check default parameters
    assert search.max_results == 5

    # Create with custom parameters
    search = WikipediaSearch(max_results=10)
    assert search.max_results == 10


def test_wikipedia_search_run(monkeypatch, mock_wikipedia_response):
    """Test Wikipedia search run method."""
    from local_deep_research.web_search_engines.wikipedia_search import WikipediaSearch

    # Mock the API response
    mock_response = Mock()
    mock_response.status_code = 200
    mock_response.json.return_value = mock_wikipedia_response

    monkeypatch.setattr("requests.get", lambda *args, **kwargs: mock_response)

    # Create the search engine and run a query
    wiki_search = WikipediaSearch(max_results=5)
    results = wiki_search.run("artificial intelligence")

    # Verify the API was called with correct parameters
    # Note: We can't directly verify requests.get arguments with monkeypatch
    # But we can verify the results structure

    # Verify results structure
    assert len(results) == 2  # Two results in mock response

    # Check first result
    assert results[0]["title"] == "Artificial intelligence"
    assert "intelligence demonstrated by machines" in results[0]["snippet"]
    # Use secure URL validation instead of simple string check
    link = results[0]["link"]
    assert link.startswith("https://en.wikipedia.org/wiki/") or link.startswith(
        "https://wikipedia.org/wiki/"
    )
    assert results[0]["source"] == "Wikipedia"


def test_wikipedia_search_error_handling(monkeypatch):
    """Test Wikipedia search error handling."""
    from local_deep_research.web_search_engines.wikipedia_search import WikipediaSearch

    # Mock a failed API response
    mock_response = Mock()
    mock_response.status_code = 500

    monkeypatch.setattr("requests.get", lambda *args, **kwargs: mock_response)

    # Create the search engine and run a query
    wiki_search = WikipediaSearch()
    results = wiki_search.run("artificial intelligence")

    # Should return empty list on error
    assert isinstance(results, list)
    assert len(results) == 0


def test_wikipedia_search_request_exception(monkeypatch):
    """Test Wikipedia search handling of request exceptions."""
    from local_deep_research.web_search_engines.wikipedia_search import WikipediaSearch

    # Mock a request exception
    def mock_get(*args, **kwargs):
        raise requests.exceptions.RequestException("Connection error")

    monkeypatch.setattr("requests.get", mock_get)

    # Create the search engine and run a query
    wiki_search = WikipediaSearch()
    results = wiki_search.run("artificial intelligence")

    # Should return empty list on exception
    assert isinstance(results, list)
    assert len(results) == 0


def test_wikipedia_search_empty_results(monkeypatch):
    """Test Wikipedia search with empty results."""
    from local_deep_research.web_search_engines.wikipedia_search import WikipediaSearch

    # Mock an empty response
    mock_response = Mock()
    mock_response.status_code = 200
    mock_response.json.return_value = {"query": {"search": []}}

    monkeypatch.setattr("requests.get", lambda *args, **kwargs: mock_response)

    # Create the search engine and run a query
    wiki_search = WikipediaSearch()
    results = wiki_search.run("nonexistent topic xyzabc123")

    # Should return empty list for no results
    assert isinstance(results, list)
    assert len(results) == 0


def test_wikipedia_search_rate_limiting(monkeypatch):
    """Test Wikipedia search rate limiting handling."""
    from local_deep_research.web_search_engines.wikipedia_search import WikipediaSearch

    # Mock a rate limited response
    mock_response = Mock()
    mock_response.status_code = 429  # Too Many Requests

    monkeypatch.setattr("requests.get", lambda *args, **kwargs: mock_response)

    # Create the search engine and run a query
    wiki_search = WikipediaSearch()
    results = wiki_search.run("artificial intelligence")

    # Should return empty list on rate limiting
    assert isinstance(results, list)
    assert len(results) == 0


def test_wikipedia_search_url_formation(monkeypatch):
    """Test that Wikipedia search forms URLs correctly."""
    from local_deep_research.web_search_engines.wikipedia_search import WikipediaSearch

    # Mock a successful response
    mock_response = Mock()
    mock_response.status_code = 200
    mock_response.json.return_value = {
        "query": {
            "search": [
                {
                    "title": "Test Page",
                    "snippet": "Test snippet content",
                    "pageid": 12345,
                }
            ]
        }
    }

    monkeypatch.setattr("requests.get", lambda *args, **kwargs: mock_response)

    # Create the search engine and run a query
    wiki_search = WikipediaSearch()
    results = wiki_search.run("test page")

    # Check that the URL was formed correctly
    assert results[0]["link"] == "https://en.wikipedia.org/wiki/Test_Page"

    # Try with a title that has spaces and special characters
    mock_response.json.return_value = {
        "query": {
            "search": [
                {
                    "title": "Artificial intelligence & ethics",
                    "snippet": "Test snippet content",
                    "pageid": 12345,
                }
            ]
        }
    }

    results = wiki_search.run("AI ethics")
    assert (
        results[0]["link"]
        == "https://en.wikipedia.org/wiki/Artificial_intelligence_%26_ethics"
    )
